{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e76a22d3fde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdayofmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdayofweek\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,dayofweek,to_timestamp,size,isnan\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: Samuels-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    if socket.gethostname() == 'FAC38c9860d5a89':\n",
    "        print('Create Local SparkSession')\n",
    "        spark = SparkSession.builder.config(\n",
    "        \"spark.driver.host\", \"localhost\").appName(\n",
    "        \"measure-tweets-sentiment\").getOrCreate()\n",
    "    else:\n",
    "        print('Create Cluster SparkSession')\n",
    "        spark = SparkSession.builder.appName(\n",
    "        \"measure-tweets-sentiment\").getOrCreate()\n",
    "    \n",
    "# Local\n",
    "print('Hostname:', socket.gethostname())\n",
    "if  'samuel' in socket.gethostname().lower():\n",
    "    path_to_tweets   = '../data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-extract/'\n",
    "    path_to_keywords = '../data/keywords/hedonometer/'\n",
    "    path_to_sentiment= '../data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-sentiment/'\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_tweets   = '/user/spf248/twitter/data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-extract/'\n",
    "    path_to_keywords = '/user/spf248/twitter/data/keywords/hedonometer/'\n",
    "    path_to_sentiment= '/user/spf248/twitter/data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-sentiment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import:\n",
      "Computing Time: 4 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import:')\n",
    "start = timer()\n",
    "\n",
    "df = spark.read.parquet(path_to_tweets)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHE DATASET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_id: string, created_at: timestamp, text: string, tweet_lang: string, user_id: string, user_location: string, place_id: string, tweet_longitude: double, tweet_latitude: double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CACHE DATASET\")\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAN TEXT\n"
     ]
    }
   ],
   "source": [
    "print(\"CLEAN TEXT\")\n",
    "\n",
    "punctuation = frozenset(list(string.punctuation)+['“','¿'])\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # REMOVE URL\n",
    "    text = \"\".join([char for char in text if char not in punctuation]) # REMOVE PUNCTUATION\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text) # REMOVE DIGITS\n",
    "    text = re.sub(r\"\\n\",\" \", text).strip() # REMOVE EXTRA LINEBREAK\n",
    "    text = re.sub(r\" +\",\" \", text).strip() # REMOVE EXTRA SPACE\n",
    "    return text.lower()\n",
    "\n",
    "clean_text_udf = udf(clean_text,StringType())\n",
    "df = df.withColumn('text',clean_text_udf('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Keywords Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages: english, french, german, indonesian, korean, portuguese, russian, spanish\n"
     ]
    }
   ],
   "source": [
    "languagenames = [\n",
    "'english',\n",
    "'french',\n",
    "'german',\n",
    "'indonesian',\n",
    "'korean',\n",
    "'portuguese',\n",
    "'russian',\n",
    "'spanish',\n",
    "]\n",
    "\n",
    "print('Languages:', ', '.join(languagenames))\n",
    "\n",
    "languagecode2languagename = {\n",
    "'en': 'english',\n",
    "'fr': 'french',\n",
    "'de': 'german',\n",
    "'id': 'indonesian',\n",
    "'ko': 'korean',\n",
    "'pt': 'portuguese',\n",
    "'ru': 'russian',\n",
    "'es': 'spanish'}\n",
    "\n",
    "languagename2keyword2score = {}\n",
    "\n",
    "for languagename in languagenames:\n",
    "\n",
    "    languagename2keyword2score[languagename] = \\\n",
    "    spark.read.option(\n",
    "    'header','true').option(\n",
    "    \"inferSchema\", \"true\").csv(\n",
    "    path_to_keywords+languagename+'-twitter.csv').toPandas().set_index('WORD')['SCORE'].to_dict()\n",
    "\n",
    "# Create Broadcast Variable\n",
    "languagecode2languagename_bc  = spark.sparkContext.broadcast(languagecode2languagename)\n",
    "languagename2keyword2score_bc = spark.sparkContext.broadcast(languagename2keyword2score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZE TEXT\n"
     ]
    }
   ],
   "source": [
    "print(\"TOKENIZE TEXT\")\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\" \")\n",
    "df = tokenizer.transform(df)\n",
    "df = df.drop('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE TOKENS\n"
     ]
    }
   ],
   "source": [
    "print(\"SCORE TOKENS\")\n",
    "\n",
    "scored_tokens_schema = StructType([\n",
    "    StructField(\"n_score\", FloatType(), False),\n",
    "    StructField(\"avg_score\", FloatType(), False)\n",
    "])\n",
    "\n",
    "def scored_tokens(tokens,languagecode):\n",
    "    \n",
    "    if languagecode in languagecode2languagename_bc.value:\n",
    "        \n",
    "        languagename = languagecode2languagename_bc.value[languagecode]\n",
    "        \n",
    "        scored_tokens = [\n",
    "        languagename2keyword2score_bc.value[languagename][token] for token in tokens \n",
    "        if token in languagename2keyword2score_bc.value[languagename]]\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            return (float(len(scored_tokens)), float(np.nanmean(scored_tokens)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return (float(np.nan), float(np.nan))\n",
    "\n",
    "scored_tokens_udf = udf(scored_tokens, scored_tokens_schema)\n",
    "\n",
    "# Compute Score Tokens\n",
    "df = df.withColumn('scored_tokens', scored_tokens_udf('tokens','tweet_lang'))\n",
    "df = df.withColumn('avg_score',F.col('scored_tokens').getItem('avg_score'))\n",
    "df = df.withColumn('n_score',F.col('scored_tokens').getItem('n_score'))\n",
    "df = df.drop('scored_tokens')\n",
    "\n",
    "# Count Tokens\n",
    "df = df.withColumn('n_tokens',size('tokens'))\n",
    "df = df.drop('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save\n",
      "Computing Time: 21 sec\n"
     ]
    }
   ],
   "source": [
    "print('SAVE TO PARQUET')\n",
    "start = timer()\n",
    "\n",
    "df.write.mode(\"overwrite\").parquet(path_to_sentiment)\n",
    "\n",
    "end = timer()\n",
    "print('DONE IN', round(end - start), 'SEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sort_values(by='tweet_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_longitude</th>\n",
       "      <th>tweet_latitude</th>\n",
       "      <th>place_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>n_score</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>tweet_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812405126879121408</td>\n",
       "      <td>811538749</td>\n",
       "      <td>vimercate (mb)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c90750b5edc76f6c</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>812405135255158785</td>\n",
       "      <td>434359026</td>\n",
       "      <td>None</td>\n",
       "      <td>-118.338292</td>\n",
       "      <td>34.101555</td>\n",
       "      <td>3b77caf94bfc81fe</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4.9840</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>812405139478810624</td>\n",
       "      <td>1864954177</td>\n",
       "      <td>Longe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68e019afec7d0ba5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>812405143673143296</td>\n",
       "      <td>2210256804</td>\n",
       "      <td>Acosando a Battler y a Kuroki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9de57b9239869b74</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>6.4000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>812405152044855296</td>\n",
       "      <td>3299672999</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228a068876235841</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>5.6475</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     user_id                  user_location  \\\n",
       "0  812405126879121408   811538749                 vimercate (mb)   \n",
       "1  812405135255158785   434359026                           None   \n",
       "2  812405139478810624  1864954177                          Longe   \n",
       "3  812405143673143296  2210256804  Acosando a Battler y a Kuroki   \n",
       "4  812405152044855296  3299672999                     Texas, USA   \n",
       "\n",
       "   tweet_longitude  tweet_latitude          place_id  year  month  \\\n",
       "0              NaN             NaN  c90750b5edc76f6c  2016     12   \n",
       "1      -118.338292       34.101555  3b77caf94bfc81fe  2016     12   \n",
       "2              NaN             NaN  68e019afec7d0ba5  2016     12   \n",
       "3              NaN             NaN  9de57b9239869b74  2016     12   \n",
       "4              NaN             NaN  228a068876235841  2016     12   \n",
       "\n",
       "   day_of_month  day_of_week  avg_score  n_score  n_tokens tweet_lang  \n",
       "0            23            6        NaN      NaN         4         it  \n",
       "1            23            6     4.9840      5.0        11         en  \n",
       "2            23            6     3.2100      2.0         4         es  \n",
       "3            23            6     6.4000      1.0         2         es  \n",
       "4            23            6     5.6475      8.0        13         en  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-from-decahose-partition-0-block-0.json.bz2'\n",
    "\n",
    "dp = pd.read_json(\n",
    "path,\n",
    "orient='records',\n",
    "dtype=False,\n",
    "precise_float=True,\n",
    "convert_dates=False)\n",
    "\n",
    "dp = dp[[\n",
    "'coordinates',\n",
    "'created_at',\n",
    "'extended_tweet',\n",
    "'id_str',\n",
    "'lang',\n",
    "'text',\n",
    "'truncated',\n",
    "'user',\n",
    "'place']].copy()\n",
    "\n",
    "dp = dp.drop_duplicates('id_str')\n",
    "\n",
    "dp['place_id'] = dp['place'].apply(lambda x:x['id'] if type(x)==dict else None)\n",
    "dp['user_id'] = dp['user'].apply(lambda x:x['id_str'])\n",
    "dp['user_location'] = dp['user'].apply(lambda x:x['location'])\n",
    "dp.drop(['user','place'],1,inplace=True)\n",
    "\n",
    "dp['year']  = pd.to_datetime(dp['created_at']).apply(lambda x:x.year)\n",
    "dp['month'] = pd.to_datetime(dp['created_at']).apply(lambda x:x.month)\n",
    "dp['day_of_month'] = pd.to_datetime(dp['created_at']).apply(lambda x:x.day)\n",
    "dp['day_of_week']  = pd.to_datetime(dp['created_at']).apply(lambda x:x.dayofweek)\n",
    "dp.drop('created_at',1,inplace=True)\n",
    "\n",
    "dp['full_text'] = dp['extended_tweet'].apply(lambda x:x['full_text'] if type(x)==dict else None)\n",
    "dp.loc[dp['truncated']==True,'text'] = dp.loc[dp['truncated']==True,'full_text']\n",
    "dp.drop(['full_text','truncated','extended_tweet'],1,inplace=True)\n",
    "\n",
    "dp['tweet_longitude'] = dp['coordinates'].apply(lambda x:x['coordinates'][0] if x else np.nan)\n",
    "dp['tweet_latitude']  = dp['coordinates'].apply(lambda x:x['coordinates'][1] if x else np.nan)\n",
    "dp.drop('coordinates',1,inplace=True)\n",
    "dp.rename(columns={'id_str':'tweet_id','lang':'tweet_lang'},inplace=True)\n",
    "\n",
    "dp['text'] = dp['text'].apply(clean_text)\n",
    "dp['tokens'] = dp['text'].apply(lambda x:x.split())\n",
    "dp.drop('text',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel.fraiberger/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Mean of empty slice\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def score_tokens(x):\n",
    "    \n",
    "    if x['tweet_lang'] in languagecode2languagename:\n",
    "        \n",
    "        languagename = languagecode2languagename[x['tweet_lang']]\n",
    "\n",
    "        scored_tokens = [\n",
    "        languagename2keyword2score[languagename][token] for token in x['tokens']\n",
    "        if token in languagename2keyword2score[languagename]]\n",
    "    \n",
    "        scores = (float(len(scored_tokens)), float(np.nanmean(scored_tokens)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        scores = (float(np.nan), float(np.nan))\n",
    "    \n",
    "    return pd.Series(scores, index = ['n_score','avg_score'])\n",
    "\n",
    "dp = pd.concat([dp,dp.apply(score_tokens,1)],1)\n",
    "dp['n_tokens'] = dp['tokens'].apply(len)\n",
    "dp.drop('tokens',1,inplace=True)\n",
    "\n",
    "dp = dp.sort_values(by='tweet_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Differences Per Column:\n",
      "Column tweet_id # obs 7560 -> value differences: 0\n",
      "Column tweet_lang # obs 7560 -> value differences: 0\n",
      "Column place_id # obs 7546 -> value differences: 0\n",
      "Column user_id # obs 7560 -> value differences: 0\n",
      "Column user_location # obs 6191 -> value differences: 0\n",
      "Column year # obs 7560 -> value differences: 0\n",
      "Column month # obs 7560 -> value differences: 0\n",
      "Column day_of_month # obs 7560 -> value differences: 0\n",
      "Column day_of_week # obs 7560 -> value differences: 7560\n",
      "Column tweet_longitude # obs 1131 -> value differences: 0\n",
      "Column tweet_latitude # obs 1131 -> value differences: 0\n",
      "Column n_score # obs 5814 -> value differences: 3\n",
      "Column avg_score # obs 5670 -> value differences: 5586\n",
      "Column n_tokens # obs 7560 -> value differences: 8\n"
     ]
    }
   ],
   "source": [
    "print('Check Differences Per Column:')\n",
    "for col in dp.columns:\n",
    "    idx = pd.concat([dp[col],ds[col]],1).dropna().index\n",
    "    print('Column', col, '# obs',idx.shape[0],'-> value differences:', (ds.loc[idx,col]!=dp.loc[idx,col]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5670.000000</td>\n",
       "      <td>5670.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.623397</td>\n",
       "      <td>5.623390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.592129</td>\n",
       "      <td>0.592136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.308616</td>\n",
       "      <td>5.308359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.589615</td>\n",
       "      <td>5.589615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.881765</td>\n",
       "      <td>5.881765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.460000</td>\n",
       "      <td>8.460000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_score    avg_score\n",
       "count  5670.000000  5670.000000\n",
       "mean      5.623397     5.623390\n",
       "std       0.592129     0.592136\n",
       "min       1.860000     1.860000\n",
       "25%       5.308616     5.308359\n",
       "50%       5.589615     5.589615\n",
       "75%       5.881765     5.881765\n",
       "max       8.460000     8.460000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'avg_score'\n",
    "pd.concat([dp[col],ds[col]],1).dropna().describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

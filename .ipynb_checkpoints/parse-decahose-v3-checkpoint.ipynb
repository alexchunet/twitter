{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lzma\n",
    "import ujson as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: None\n",
      "Month: 12\n",
      "# Input Files: 4\n",
      "Output File: user-id-v3-12.csv\n"
     ]
    }
   ],
   "source": [
    "######################## Params #############################\n",
    "\n",
    "version = 'v3'\n",
    "month   = '01'\n",
    "year    = None\n",
    "\n",
    "print('Year:', year)\n",
    "print('Month:', month)\n",
    "\n",
    "# path_to_input_files  = './data/decahose/'\n",
    "# path_to_output_files = './data/decahose/'\n",
    "path_to_input_files  = '/net/twitter/gardenhose-data/json/'\n",
    "path_to_output_files = './data/decahose/users/'\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Get Output File\n",
    "def get_output_file(version,year=None,month=None):\n",
    "    \n",
    "    output_file = 'user-id-'+version\n",
    "    \n",
    "    if year:\n",
    "        output_file += '-'+str(year)\n",
    "        \n",
    "    if month:\n",
    "        output_file += '-'+str(month)\n",
    "        \n",
    "    output_file+='.csv'\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# Select Input Files\n",
    "def get_input_files(path_to_input_files,year=None,month=None):\n",
    "\n",
    "    input_files = [file for file in os.listdir(path_to_input_files) if file[-3:]=='.xz']\n",
    "    \n",
    "    if year:\n",
    "        input_files = [file for file in input_files if file.replace('.','-').split('-')[2]==year]\n",
    "\n",
    "    if month:\n",
    "        input_files = [file for file in input_files if file.replace('.','-').split('-')[3]==month]\n",
    "\n",
    "    # Randomize For Parallel Processing\n",
    "    return np.random.permutation(input_files)\n",
    "\n",
    "input_files = get_input_files(path_to_input_files,year,month)\n",
    "print('# Input Files:', len(input_files))\n",
    "\n",
    "output_file = get_output_file(version,year,month)\n",
    "print('Output File:', output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tweets(xz_file):\n",
    "    \n",
    "    tweets  = []\n",
    "    \n",
    "    with lzma.open(path_to_input_files+xz_file,'rb') as f:\n",
    "\n",
    "        for line in f:\n",
    "\n",
    "            # Only Select Tweets With Geocoordinates (Could Be in the Replies)\n",
    "            if b'\"coordinates\":{' in line:\n",
    "                \n",
    "                # Json Parsing Can Fail\n",
    "                try:\n",
    "                    tweet = json.loads(line.decode(\"utf-8\"))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # Only Selects Geocoordinates If Any and User Info from the Original Tweet\n",
    "                if tweet.get('coordinates',None):\n",
    "\n",
    "                    tweets.append([\n",
    "                    tweet['user']['id_str'],\n",
    "                    tweet['coordinates']['coordinates'][1], \n",
    "                    tweet['coordinates']['coordinates'][0], \n",
    "                    ])\n",
    "\n",
    "    return pd.DataFrame(tweets, columns=['user_id','latitude','longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Tweets...\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "print('Parse Tweets...')\n",
    "with mp.Pool() as pool:\n",
    "    tweets = pool.map(parse_tweets, input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tweets: 4552\n",
      "# Users: 1072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.concat(tweets)\n",
    "users  = tweets.groupby('user_id').agg({'latitude':'mean','longitude':'mean',})\n",
    "\n",
    "print('# Tweets:', tweets.shape[0])\n",
    "print('# Users:', users.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save User Ids:\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Save User Ids...')\n",
    "users.to_csv(path_to_output_files+output_file)\n",
    "print('Done!')\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

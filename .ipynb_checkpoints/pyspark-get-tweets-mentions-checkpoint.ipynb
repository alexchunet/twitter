{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,dayofweek,to_timestamp,size,isnan\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = \"US\"\n",
    "language_code = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: Samuels-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    if 'samuel' in socket.gethostname().lower():\n",
    "        print('Create Local SparkSession')\n",
    "        spark = SparkSession.builder.config(\n",
    "        \"spark.driver.host\", \"localhost\").appName(\n",
    "        \"get-tweets-mentions\").getOrCreate()\n",
    "    else:\n",
    "        print('Create Cluster SparkSession')\n",
    "        spark = SparkSession.builder.appName(\n",
    "        \"get-tweets-mentions\").getOrCreate()\n",
    "    \n",
    "# Local\n",
    "print('Hostname:', socket.gethostname())\n",
    "if  'samuel' in socket.gethostname().lower():\n",
    "    path_to_tweets   = '../data/decahose/parsed/tweets/tweets-with-identified-location-'+country_code+'/'\n",
    "#     path_to_tweets   = '../data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-extract/'\n",
    "    path_to_mentions = '../data/decahose/parsed/tweets/tweets-with-identified-location-mentions/'\n",
    "    path_to_locations = '../data/decahose/parsed/locations/'\n",
    "    path_to_keywords = '../data/keywords/labor/lang/'\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_tweets   = '/user/spf248/twitter/data/decahose/parsed/tweets/tweets-with-identified-location-'+country_code+'/'\n",
    "#     path_to_tweets   = '/user/spf248/twitter/data/decahose/parsed/tweets/tweets-with-geocoordinates-or-place-extract/'\n",
    "    path_to_mentions = '/user/spf248/twitter/data/decahose/parsed/tweets/tweets-with-identified-location-mentions/'\n",
    "    path_to_locations = '/user/spf248/twitter/data/decahose/parsed/locations/' \n",
    "    path_to_keywords = '/user/spf248/twitter/data/keywords/labor/lang/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Dataset\n"
     ]
    }
   ],
   "source": [
    "print('Import Dataset')\n",
    "df = spark.read.parquet(path_to_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_id: string, created_at: timestamp, text: string, tweet_lang: string, user_id: string, user_location: string, place_id: string, tweet_longitude: double, tweet_latitude: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cache\")\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Mentions\n",
      "# Mentions: 22\n"
     ]
    }
   ],
   "source": [
    "print('Import Mentions')\n",
    "mentions = spark.read.option('header','true').csv(path_to_keywords+language_code)\n",
    "mentions = list(mentions.toPandas()['mention'])\n",
    "print('# Mentions:',len(mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Identified Locations\n"
     ]
    }
   ],
   "source": [
    "print('Import Identified Locations')\n",
    "identified_locations = spark.read.option('header','true').option(\"multiLine\", \"true\").csv(path_to_locations+'account-locations-identified.csv')\n",
    "identified_locations = identified_locations.where(identified_locations.country_short == country_code)\n",
    "identified_locations = identified_locations.select(col('LOCATION').alias('user_location'),col('_c0').alias('location_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWERCASE\n",
      "SELECT LANGUAGE\n",
      "EXTRACT YEAR AND MONTH\n",
      "# OBS: 3583\n",
      "Merge Location Id\n",
      "# OBS: 1215\n",
      "anyone hiring?\n",
      "i am unemployed\n",
      "Append Constant Column\n"
     ]
    }
   ],
   "source": [
    "print(\"LOWERCASE\")\n",
    "df = df.withColumn('text', F.lower(F.col('text')))\n",
    "\n",
    "print(\"SELECT LANGUAGE\")\n",
    "df = df.where(df.tweet_lang == language_code)\n",
    "\n",
    "print(\"EXTRACT YEAR AND MONTH\")\n",
    "df = df.withColumn('year', year('created_at').cast(\"string\"))\n",
    "df = df.withColumn('month', month('created_at').cast(\"string\"))\n",
    "\n",
    "print(\"# OBS:\", df.count())\n",
    "# OBS: 2380339155\n",
    "\n",
    "print('Merge Location Id')\n",
    "df = df.join(identified_locations, on=['user_location'], how='inner')\n",
    "\n",
    "print(\"# OBS:\", df.count())\n",
    "\n",
    "for mention in mentions:\n",
    "    print(mention)\n",
    "    field_mention = 'mention_'+mention.replace(' ','_')\n",
    "    df = df.withColumn(field_mention, df.text.contains(mention).cast(\"int\"))\n",
    "    \n",
    "print('Append Constant Column')\n",
    "df = df.withColumn('n_tweets', lit(1))\n",
    "\n",
    "df = df.drop('tweet_id','created_at','tweet_lang','user_id','place_id','tweet_longitude','tweet_latitude','user_location','text')\n",
    "\n",
    "print(\"COUNT TWEETS AND MENTIONS BY YEAR MONTH AND USER LOCATION\")\n",
    "df = df.groupBy('year','month','location_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE TO CSV\n",
      "DONE IN 1 SEC\n"
     ]
    }
   ],
   "source": [
    "print('SAVE TO CSV')\n",
    "start = timer()\n",
    "\n",
    "df.coalesce(1).write.mode(\"overwrite\").csv(path_to_mentions+country_code+'.csv',header=True)\n",
    "\n",
    "end = timer()\n",
    "print('DONE IN', round(end - start), 'SEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

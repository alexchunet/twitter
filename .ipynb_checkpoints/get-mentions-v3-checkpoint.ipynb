{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from timeit import default_timer as timer\n",
    "import glob\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Processes: 4\n",
      "Countries:\n",
      "\n",
      "Indonesia\n",
      "Malaysia\n",
      "Myanmar\n",
      "Pakistan\n",
      "Saudi Arabia\n",
      "Thailand\n"
     ]
    }
   ],
   "source": [
    "version_mentions  = 'v3'\n",
    "\n",
    "path_to_timelines = './data/timelines/'\n",
    "path_to_locations = './data/decahose/parsed/locations/'\n",
    "path_to_keywords  = './data/keywords/'\n",
    "path_to_mentions  = './data/mentions/'\n",
    "\n",
    "n_processes = mp.cpu_count()\n",
    "print('# Processes:', n_processes)\n",
    "    \n",
    "if not os.path.exists(path_to_mentions):\n",
    "    os.mkdir(path_to_mentions)\n",
    "       \n",
    "countries = sorted(set([x.split('-')[0].title() for x in os.listdir(path_to_timelines) if '-' in x]))\n",
    "\n",
    "print('Countries:\\n')\n",
    "print('\\n'.join(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = {\n",
    "'Argentina':['perdí mi trabajo','perdi mi trabajo','acabo de perder mi trabajo','me despidieron','acabo de ser despedido'],\n",
    "'Brazil':['eu perdi meu emprego','acabei de perder meu emprego','fui demitido','acabei de ser demitido'], \n",
    "'Chile':['perdí mi trabajo','perdi mi trabajo','acabo de perder mi trabajo','me despidieron','acabo de ser despedido'],\n",
    "'Colombia':['perdí mi trabajo','perdi mi trabajo','acabo de perder mi trabajo','me despidieron','acabo de ser despedido'],\n",
    "'United Arab Emirates':['لقد فقدت وظيفتي','تم طردي','أنا فقط حصلت على النار'],\n",
    "'Kuwait':['لقد فقدت وظيفتي','تم طردي','أنا فقط حصلت على النار'],\n",
    "'Indonesia':['saya kehilangan pekerjaan','saya baru saja kehilangan pekerjaan','saya dipecat','saya baru saja dipecat'],\n",
    "'Malaysia':['saya kehilangan pekerjaan saya','saya baru sahaja kehilangan pekerjaan saya','saya dipecat','saya telah dipecat','saya baru sahaja dipecat'],\n",
    "'Philippines':['nawalan ako ng trabaho','nawala ko lang ang trabaho ko'],\n",
    "'Qatar':['لقد فقدت وظيفتي','تم طردي','أنا فقط حصلت على النار'],\n",
    "'Saudi Arabia':['لقد فقدت وظيفتي','تم طردي','أنا فقط حصلت على النار'],\n",
    "'Thailand':['ฉันตกงาน','ฉันเพิ่งตกงาน','ฉันโดนไล่ออก','ฉันเพิ่งถูกไล่ออก'],\n",
    "}\n",
    "\n",
    "# pd.Series(all_keywords).to_csv('./data/keywords/keywords-v3.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(country):\n",
    "    \n",
    "    return pd.concat([\n",
    "    pd.read_pickle(file) for file in glob.glob(path_to_locations+'locations*')]).loc[country].index\n",
    "\n",
    "def get_paths_to_timelines(country):\n",
    "    \n",
    "    return glob.glob(path_to_timelines+country.lower()+'*'+'/*'+country.lower()+'*.pkl')\n",
    "\n",
    "def get_mentions(locations,keywords,paths_to_timelines,n_blocks,index_block):\n",
    "    \n",
    "    cols = ['TIME','USER LOCATION','TEXT']\n",
    "    \n",
    "    timelines = pd.DataFrame()\n",
    "    \n",
    "    for path_to_timeline in paths_to_timelines[n_blocks*index_block:n_blocks*(index_block+1)]:\n",
    "        \n",
    "        timeline = pd.read_pickle(path_to_timeline)[cols]\n",
    "\n",
    "        dates = timeline['TIME'].apply(lambda x:x.split())\n",
    "        timeline['YEAR']  = dates.apply(lambda x:x[-1])\n",
    "        timeline['MONTH'] = dates.apply(lambda x:x[1])\n",
    "\n",
    "        # Select Timeline With Identified Locations\n",
    "        timeline = timeline.loc[timeline['USER LOCATION'].isin(locations)].copy()\n",
    "\n",
    "        if len(timeline):\n",
    "            \n",
    "            timeline['TEXT'] = timeline['TEXT'].apply(lambda x:x.lower().replace('#',''))\n",
    "\n",
    "            for keyword in keywords:\n",
    "\n",
    "                timeline[keyword.lower()] = \\\n",
    "                timeline['TEXT'].apply(lambda x:int(keyword.lower() in x))\n",
    "\n",
    "            timeline['COUNT'] = 1\n",
    "\n",
    "            timelines = pd.concat([timelines,\n",
    "            timeline.drop(['TEXT','TIME'],1)],sort=True).groupby(\n",
    "            ['YEAR','MONTH','USER LOCATION'],as_index=False).sum()\n",
    "        \n",
    "    return timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(country):\n",
    "   \n",
    "    print('Country:', country)\n",
    "    \n",
    "    locations = get_locations(country)\n",
    "    print('# Identified Locations:',len(locations))\n",
    "\n",
    "    keywords = all_keywords[country]\n",
    "    print('# Keywords:',len(keywords))\n",
    "\n",
    "    paths_to_timelines = get_paths_to_timelines(country)\n",
    "    print('# Timelines:',len(paths_to_timelines))\n",
    "    \n",
    "    users = [x.split('/')[-1].split('-')[0] for x in paths_to_timelines]\n",
    "    if len(set(users)) != len(users):\n",
    "        print('Check Repeated Users...Exit')\n",
    "        sys.exit(0)\n",
    "    del users\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Split Timelines By Block\n",
    "    n_blocks = len(paths_to_timelines)//n_processes + len(paths_to_timelines)%n_processes\n",
    "    print('# Users by Block:', n_blocks)  \n",
    "\n",
    "    print('Collect Mentions...')\n",
    "    with mp.Pool(processes = n_processes) as pool:\n",
    "        \n",
    "        partial_mentions = partial(get_mentions, locations, keywords, paths_to_timelines, n_blocks) \n",
    "        \n",
    "        mentions = pd.concat(pool.map(partial_mentions, range(n_processes))).groupby(\n",
    "        ['YEAR','MONTH','USER LOCATION'],as_index=False).sum()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Computing Time:', round(end - start,2), 'sec')\n",
    "    \n",
    "    print('# Obs:', int(mentions.drop(['YEAR','MONTH','USER LOCATION','COUNT'],1).values.sum()))\n",
    "    print('# Mentions:', mentions['COUNT'].sum())\n",
    "\n",
    "    print('Save Timelines...')\n",
    "    start = timer()\n",
    "\n",
    "    mentions.to_pickle(path_to_mentions+'mentions-'+country.lower()+'-'+version_mentions+'.pkl',compression='xz')\n",
    "    del mentions\n",
    "    \n",
    "    end = timer()   \n",
    "    print('Computing Time:', round(end - start,2), 'sec')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactive Mode\n",
      "Country: Malaysia\n",
      "# Identified Locations: 504\n",
      "# Keywords: 5\n",
      "# Timelines: 14\n",
      "# Users by Block: 5\n",
      "Collect Mentions...\n",
      "Computing Time: 0.66 sec\n",
      "# Obs: 0\n",
      "# Mentions: 9162\n",
      "Save Timelines...\n",
      "Computing Time: 0.02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "try:\n",
    "    get_ipython().__class__.__name__\n",
    "    print('Interactive Mode')\n",
    "    main(countries[1])\n",
    "except:\n",
    "    main(sys.argv[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import itertools\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "import uuid\n",
    "import numpy as np\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/sfraiberger/data/timelines'\n",
    "path_to_timelines = '../data/timelines/'\n",
    "chunksize = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data...\n",
      "Computing Time: 23 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Import Data...')\n",
    "\n",
    "timeline_paths = pd.read_csv(path_to_timelines+'timelines-achtung.txt',header=None,squeeze=True)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Keep Pickle Files...\n",
      "Computing Time: 8 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Only Keep Pickle Files...')\n",
    "\n",
    "timeline_paths = timeline_paths.loc[\n",
    "timeline_paths.apply(lambda x:'pkl' in x)].rename('path').reset_index(drop=True).copy()\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Directory...\n",
      "Computing Time: 41 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Extract Directory...')\n",
    "\n",
    "timeline_paths = pd.concat([\n",
    "timeline_paths,\n",
    "timeline_paths.str.extract('\\./([a-z\\s]+-v\\d)/')[0].rename('directory'),\n",
    "],1)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupby List...\n",
      "Computing Time: 6 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Groupby List...')\n",
    "\n",
    "directory2path = timeline_paths.groupby(['directory'])['path'].apply(list)\n",
    "del timeline_paths\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_list(x):\n",
    "    np.random.seed(0)\n",
    "    return list(np.random.permutation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupby List...\n",
      "Computing Time: 32 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Spilt Lists in Chunks...')\n",
    "\n",
    "directory2path = directory2path.apply(randomize_list)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory2path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-94675b5190e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdirectory2path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'directory2path' is not defined"
     ]
    }
   ],
   "source": [
    "directory2path.apply(len).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupby Split Lists By Chunks...\n",
      "Computing Time: 1 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Groupby Split Lists By Chunks...')\n",
    "\n",
    "directory2pathlists = directory2path.apply(lambda x:list(chunks(x,chunksize)))\n",
    "del directory2path\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Chunks...\n",
      "../data/timelines/timelines-chunk-argentina-v2-0\n",
      "../data/timelines/timelines-chunk-argentina-v2-1\n",
      "../data/timelines/timelines-chunk-brazil-v2-0\n",
      "../data/timelines/timelines-chunk-brazil-v2-1\n",
      "../data/timelines/timelines-chunk-brazil-v2-2\n",
      "../data/timelines/timelines-chunk-brazil-v2-3\n",
      "../data/timelines/timelines-chunk-indonesia-v1-0\n",
      "../data/timelines/timelines-chunk-indonesia-v1-1\n",
      "../data/timelines/timelines-chunk-indonesia-v1-2\n",
      "../data/timelines/timelines-chunk-indonesia-v2-0\n",
      "../data/timelines/timelines-chunk-indonesia-v2-1\n",
      "../data/timelines/timelines-chunk-indonesia-v2-2\n",
      "../data/timelines/timelines-chunk-indonesia-v2-3\n",
      "../data/timelines/timelines-chunk-indonesia-v2-4\n",
      "../data/timelines/timelines-chunk-indonesia-v2-5\n",
      "../data/timelines/timelines-chunk-indonesia-v2-6\n",
      "../data/timelines/timelines-chunk-indonesia-v2-7\n",
      "../data/timelines/timelines-chunk-saudi-arabia-v4-0\n",
      "../data/timelines/timelines-chunk-saudi-arabia-v4-1\n",
      "../data/timelines/timelines-chunk-saudi-arabia-v4-2\n",
      "Computing Time: 44 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Save Chunks...')\n",
    "\n",
    "for directory in directory2pathlists.index:\n",
    "    for i,filelist in enumerate(directory2pathlists.loc[directory]):\n",
    "        \n",
    "        filename_chunk = path_to_timelines+'timelines-chunk-'+directory.replace(' ','-')+'-'+str(i)\n",
    "        print(filename_chunk)\n",
    "        \n",
    "        pd.Series([x for x in filelist]).to_csv(filename_chunk,header=False,index=False)\n",
    "        \n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = timer()\n",
    "# print('Match Filename Pattern...')\n",
    "\n",
    "# match = timeline_paths.str.extract('\\./([a-z\\s]+)-v(\\d)/(\\d+)-([a-z\\s]+)-v(\\d).pkl')\n",
    "# match.columns=['country 1','version 1','user','country 2','version 2']\n",
    " \n",
    "# if match.shape[1]!=5:\n",
    "#     print('Error Parsing Some Files')\n",
    "\n",
    "# for col in match.columns:\n",
    "#     if match[col].count()!=match.shape[0]:\n",
    "#         print('Missing Value in', col)\n",
    "        \n",
    "# if (match['country 1']!=match['country 2']).sum():\n",
    "#     print('Mismatch country')\n",
    "    \n",
    "# if (match['version 1']!=match['version 2']).sum():\n",
    "#     print('Mismatch version')\n",
    "      \n",
    "# end = timer()\n",
    "# print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hostname2country={\n",
    "# 'achtung02':'Argentina',\n",
    "# 'achtung03':'Brazil',\n",
    "# 'achtung04':'Indonesia',\n",
    "# 'achtung05':'Saudi Arabia',\n",
    "# }\n",
    "\n",
    "# print('# Countries:', len(hostname2country))\n",
    "\n",
    "# hostname = socket.gethostname()\n",
    "# print('Hostname:', hostname)\n",
    "\n",
    "# country = hostname2country.get(hostname,0)\n",
    "# print('Index Partition:', country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_users     = '../data/decahose/parsed/users/'\n",
    "# path_to_locations = '../data/decahose/parsed/locations/'\n",
    "# path_to_timelines = '../data/timelines/'\n",
    "\n",
    "# block_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = timer()\n",
    "# print('Import Data...')\n",
    "\n",
    "# users_by_account_location = pd.read_pickle(path_to_users+'users-by-account-location.pkl.xz')\n",
    "# account_locations         = pd.read_pickle(path_to_locations+'account-locations-identified.pkl')\n",
    "# timeline_paths            = pd.read_csv(path_to_timelines+'timelines.txt',header=None,squeeze=True)\n",
    "\n",
    "# end = timer()\n",
    "# print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_users(country):\n",
    "    \n",
    "#     return sorted(frozenset(itertools.chain.from_iterable(\n",
    "#     users_by_account_location.reindex(\n",
    "#     account_locations.loc[account_locations['country_long']==country,'LOCATION']).dropna().to_list())))\n",
    "\n",
    "# start = timer()\n",
    "# print('Get Users...')\n",
    "\n",
    "# country_users = get_users(country)\n",
    "# print('# Country Users:', len(country_users))\n",
    "\n",
    "# del users_by_account_location, account_locations\n",
    "\n",
    "# end = timer()\n",
    "# print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_timelines(country,users):\n",
    "    \n",
    "#     np.random.seed(0)\n",
    "#     return list(np.random.permutation(timeline_paths.loc[match.loc[match['user'].isin(users)].index].apply(\n",
    "#     lambda x:path_to_timelines+x.strip('./')).tolist()))\n",
    "\n",
    "# start = timer()\n",
    "# print('Get Timelines...')\n",
    "\n",
    "# country_paths = get_timelines(country,country_users)\n",
    "# print('# Country Timelines:', len(country_paths))\n",
    "# del timeline_paths, match\n",
    "\n",
    "# end = timer()\n",
    "# print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timelines = pd.DataFrame()\n",
    "\n",
    "# start = timer()\n",
    "# print('Save By Block...')\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for j,country_path in enumerate(country_paths):\n",
    "         \n",
    "#     try:\n",
    "#         timelines = pd.concat([timelines, pd.read_pickle(country_path)],sort=False)\n",
    "#     except:\n",
    "#         print('Error Importing', country_path)\n",
    "#         continue\n",
    "\n",
    "#     # Save if Next Index is a Multiple of <size> or Reading Last File\n",
    "#     if not (i+1)%block_size or country_path==country_paths[-1]:\n",
    "        \n",
    "#         print('Ingested',j,'Files')\n",
    "#         print('Saving',i,'Files')\n",
    "\n",
    "#         timelines.to_csv(\n",
    "#         path_to_timelines+'timelines-'+country.lower().replace(' ','-')+'-'+str(uuid.uuid4())+'.csv.bz2', \n",
    "#         sep=',', \n",
    "#         line_terminator='\\n')\n",
    "        \n",
    "#         # Reset\n",
    "#         timelines = pd.DataFrame()\n",
    "#         i = 0\n",
    "        \n",
    "#         end = timer()\n",
    "#         print('Computing Time:', round(end - start), 'sec')\n",
    "#         start = timer()\n",
    "    \n",
    "#     i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

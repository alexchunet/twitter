{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,desc,row_number,col,year,month,dayofmonth,dayofweek,to_timestamp,size,isnan,lit,lower\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US\n"
     ]
    }
   ],
   "source": [
    "country_code = \"US\"\n",
    "country_name = \"united-states\"\n",
    "language_code = \"en\"\n",
    "print(country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: Samuels-MacBook-Pro.local\n",
      "../../data/decahose/parsed/tweets/tweets-with-identified-location-US\n",
      "../../data/timelines/extract/united-states\n",
      "../../data/mentions\n",
      "../../data/keywords/labor/lang\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    if 'samuel' in socket.gethostname().lower():\n",
    "        print('Create Local SparkSession')\n",
    "        spark = SparkSession.builder.config(\n",
    "        \"spark.driver.host\", \"localhost\").appName(\n",
    "        \"get-tweets-mentions\").getOrCreate()\n",
    "    else:\n",
    "        print('Create Cluster SparkSession')\n",
    "        spark = SparkSession.builder.appName(\n",
    "        \"get-tweets-mentions\").getOrCreate()\n",
    "    \n",
    "# Local\n",
    "print('Hostname:', socket.gethostname())\n",
    "if  'samuel' in socket.gethostname().lower():\n",
    "    path_to_data='../../data'\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_data='/user/spf248/twitter/data'\n",
    "    \n",
    "path_to_tweets=os.path.join(path_to_data,'decahose/parsed/tweets/tweets-with-identified-location-'+country_code)\n",
    "path_to_timelines=os.path.join(path_to_data,'timelines','extract',country_name)\n",
    "path_to_mentions=os.path.join(path_to_data,'mentions')\n",
    "path_to_keywords=os.path.join(path_to_data,'keywords/labor/lang')\n",
    "print(path_to_tweets)\n",
    "print(path_to_timelines)\n",
    "print(path_to_mentions)\n",
    "print(path_to_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Datasets\n"
     ]
    }
   ],
   "source": [
    "print('Import Datasets')\n",
    "tweets=spark.read.parquet(path_to_tweets)\n",
    "timelines=spark.read.parquet(path_to_timelines)\n",
    "df=tweets.unionByName(timelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHE\n",
      "REPARTITION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet_id: string, created_at: timestamp, text: string, tweet_lang: string, user_id: string, user_location: string, place_id: string, tweet_longitude: string, tweet_latitude: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CACHE\")\n",
    "df.cache()\n",
    "\n",
    "print(\"REPARTITION\")\n",
    "df.repartition(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP DUPLICATES\n",
      "LOWERCASE\n",
      "SELECT LANGUAGE\n",
      "EXTRACT YEAR AND MONTH\n"
     ]
    }
   ],
   "source": [
    "print(\"DROP DUPLICATES\")\n",
    "df=df.drop_duplicates(subset=['tweet_id'])\n",
    "\n",
    "print(\"LOWERCASE\")\n",
    "df = df.withColumn('text',lower(col('text')))\n",
    "\n",
    "print(\"SELECT LANGUAGE\")\n",
    "df = df.where(df.tweet_lang==language_code)\n",
    "\n",
    "print(\"EXTRACT YEAR AND MONTH\")\n",
    "df = df.withColumn('year', year('created_at').cast(\"string\"))\n",
    "df = df.withColumn('month', month('created_at').cast(\"string\"))\n",
    "df = df.withColumn('day', dayofmonth('created_at').cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT MENTIONS\n",
      "# Mentions: 22\n",
      "anyone hiring?\n",
      "i am unemployed\n",
      "i got fired\n",
      "i got laid off\n",
      "i have been fired\n",
      "i have been laid off\n",
      "i have gotten laid off\n",
      "i was fired\n",
      "i was laid off\n",
      "i've been fired\n",
      "i've been laid off\n",
      "i've gotten laid off\n",
      "looking for a job\n",
      "looking for a new job\n",
      "lost my job\n",
      "need a job\n",
      "need a new job\n",
      "need help finding a job\n",
      "searching for a job\n",
      "searching for a new job\n",
      "who is hiring\n",
      "whoâ€™s hiring\n"
     ]
    }
   ],
   "source": [
    "print('IMPORT MENTIONS')\n",
    "mentions=spark.read.option('header','true').csv(os.path.join(path_to_keywords,language_code))\n",
    "mentions=list(mentions.toPandas()['mention'])\n",
    "print('# Mentions:',len(mentions))\n",
    "print('\\n'.join(mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOKUP MENTIONS\n"
     ]
    }
   ],
   "source": [
    "print('LOOKUP MENTIONS')\n",
    "for mention in mentions:\n",
    "    field_mention='n_'+mention.replace(' ','_').replace('?','_')\n",
    "    df=df.withColumn(field_mention, df.text.contains(mention).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPEND CONSTANT\n",
      "COUNT TWEETS AND MENTIONS BY YEAR, MONTH, LOCATION, AND USER\n"
     ]
    }
   ],
   "source": [
    "print('APPEND CONSTANT')\n",
    "df=df.withColumn('n_tweets', lit(1))\n",
    "\n",
    "df=df.drop('tweet_id','created_at','tweet_lang','place_id','tweet_longitude','tweet_latitude','text')\n",
    "\n",
    "print(\"COUNT TWEETS AND MENTIONS BY YEAR, MONTH, LOCATION, AND USER\")\n",
    "df=df.groupBy('year','month','day','user_location','user_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAVE')\n",
    "start = timer()\n",
    "\n",
    "df.coalesce(1).write.mode(\"overwrite\").json(os.path.join(path_to_mentions,country_code+'-json'))\n",
    "\n",
    "end = timer()\n",
    "print('DONE IN', round(end - start), 'SEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Time (in hour): 0.35\n"
     ]
    }
   ],
   "source": [
    "print('Computing Time (in hour):',round((1580139947404-1580138670777)/(1000*3600),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
